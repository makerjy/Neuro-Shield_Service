"""
utils.py
Alzheimer's Disease Pipeline â€” ì „ì²˜ë¦¬ Â· ëª¨ë¸ Â· ì˜ˆì¸¡ ìœ í‹¸ë¦¬í‹°
=============================================================
[íŒŒì´í”„ë¼ì¸ ì „ì²´ íë¦„]
  MRI ì´ë¯¸ì§€  â†’ CNN (EfficientNetB3)  â”€â”
                                        â”œâ†’ ì•™ìƒë¸” â†’ MCI/AD ë¶„ë¥˜
  ì„ìƒ ë°ì´í„° â†’ ANN (5-seed ì•™ìƒë¸”)  â”€â”˜
                    â”‚
                    â””â”€â”€ MCI í™˜ìë§Œ â†’ RSF ìƒì¡´ ë¶„ì„ â†’ ê°œì¸ë³„ ì „í™˜ í™•ë¥  (12/24/36/48ê°œì›”)
"""

# â”€â”€ í˜¸í™˜ì„± íŒ¨ì¹˜ (Python 3.10 + ìµœì‹  scipy í™˜ê²½) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import datetime
import scipy.integrate
if not hasattr(datetime, "UTC"):
    datetime.UTC = datetime.timezone.utc
if not hasattr(scipy.integrate, "trapz"):
    scipy.integrate.trapz = scipy.integrate.trapezoid

# â”€â”€ í‘œì¤€ ì„í¬íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os
import pickle
import warnings
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use("Agg")           # ì„œë²„ í™˜ê²½(í™”ë©´ ì—†ìŒ)ì—ì„œë„ ë™ì‘
import joblib
import tensorflow as tf
from tensorflow import keras
from sklearn.preprocessing import StandardScaler
from sklearn.experimental import enable_iterative_imputer  # noqa
from sklearn.impute import IterativeImputer

warnings.filterwarnings("ignore")
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. ìƒìˆ˜ / í”¼ì²˜ ì •ì˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

IMG_SIZE = (224, 224)
CNN_WEIGHT = 0.4        # ì•™ìƒë¸” ê°€ì¤‘ì¹˜: CNN
ANN_WEIGHT = 0.6        # ì•™ìƒë¸” ê°€ì¤‘ì¹˜: ANN
CNN_AD_IDX = 1          # CNN ì¶œë ¥ í´ë˜ìŠ¤ ìˆœì„œ: 0=CN, 1=DM(AD), 2=MCI

MH_COLS = [
    "MH10GAST", "MH11HEMA", "MH12RENA", "MH13ALLE", "MH14ALCH", "MH15DRUG",
    "MH16SMOK", "MH17MALI", "MH18SURG", "MH19OTHR", "MH2NEURL", "MH3HEAD",
    "MH4CARD",  "MH5RESP",  "MH6HEPAT", "MH7DERM",  "MH8MUSCL", "MH9ENDO",
    "MHPSYCH",
]

# MICE ì„í“¨í„°ê°€ ì‚¬ìš©í•˜ëŠ” ë² ì´ìŠ¤ í”¼ì²˜ (ìˆœì„œ ê³ ì •)
BASE_FEATS = [
    "entry_age", "PTGENDER",
    "MH10GAST", "MH11HEMA", "MH12RENA", "MH13ALLE", "MH14ALCH", "MH15DRUG",
    "MH16SMOK", "MH17MALI", "MH18SURG", "MH19OTHR", "MH2NEURL", "MH3HEAD",
    "MH4CARD",  "MH5RESP",  "MH6HEPAT", "MH7DERM",  "MH8MUSCL", "MH9ENDO",
    "MHPSYCH",  "COG_DISORDER", "dementia_med", "antidepressant_med",
    "CDRSB", "MMSCORE", "FAQTOTAL", "LDELTOTAL", "VSBPSYS",
]

COG_COLS    = ["CDRSB", "MMSCORE", "FAQTOTAL", "LDELTOTAL"]
ENG_FEATS   = ["FAQ_LDELTA_ratio", "high_risk_score", "med_cog_risk",
               "CDRSB_MMSE_ratio", "cog_composite"]
HEALTH_COLS = [c for c in BASE_FEATS if c not in COG_COLS]   # 25ê°œ
ALL_FEATS   = HEALTH_COLS + COG_COLS + ENG_FEATS              # 34ê°œ
H_DIM, C_DIM, E_DIM = len(HEALTH_COLS), len(COG_COLS), len(ENG_FEATS)

# RSF í”¼ì²˜ (ìƒì¡´ ë¶„ì„ìš©)
RSF_FEATS = [
    "entry_age", "APOE4_Count",
    "mmse_baseline", "cdrsb_baseline",
    "mmse_slope",    "cdrsb_slope",
    "mmse_std",      "cdrsb_std",
    "mmse_total_change", "cdrsb_total_change",
]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. ëª¨ë¸ ë¡œë”©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def build_cnn(weights_path: str) -> keras.Model:
    """
    EfficientNetB3 ê¸°ë°˜ CNN ì¬ê±´ + ê°€ì¤‘ì¹˜ ë¡œë“œ.
    Sequential ì—­ì§ë ¬í™” ë²„ê·¸ë¥¼ ìš°íšŒí•˜ê¸° ìœ„í•´ Functional APIë¡œ ìˆ˜ë™ ì¬ê±´.
    ì¶œë ¥: softmax(3) â€” 0:CN, 1:DM(AD), 2:MCI
    """
    inputs  = keras.Input(shape=(*IMG_SIZE, 3))
    base    = keras.applications.EfficientNetB3(
        include_top=False, weights=None, pooling="max"
    )
    x = base(inputs)
    x = keras.layers.BatchNormalization(
        axis=-1, momentum=0.99, epsilon=0.0001, name="batch_normalization_2"
    )(x)
    x = keras.layers.Dense(256, activation="relu",    name="dense_4")(x)
    x = keras.layers.Dropout(0.5,                     name="dropout_2")(x)
    out = keras.layers.Dense(3, activation="softmax", name="dense_5")(x)
    model = keras.Model(inputs=inputs, outputs=out)
    model.load_weights(weights_path)
    return model


def load_ann_models(ann_paths: list[str]) -> list:
    """5-seed binary ANN ëª¨ë¸ ë¡œë“œ. ì¶œë ¥: sigmoid(1) â€” P(AD)"""
    models = [keras.models.load_model(p, compile=False) for p in ann_paths]
    return models


def load_preprocessing_tools(imputer_path: str, scaler_path: str):
    """MICE Imputer + StandardScaler ë¡œë“œ"""
    with open(imputer_path, "rb") as f:
        imputer = pickle.load(f)
    with open(scaler_path, "rb") as f:
        scaler = pickle.load(f)
    return imputer, scaler


def load_survival_models(rsf_path: str, rsf_scaler_path: str):
    """
    ì‚¬ì „ í•™ìŠµëœ RSF ëª¨ë¸ + RSFìš© ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ.
    ì—†ìœ¼ë©´ None ë°˜í™˜ â†’ run_pipeline.py ì—ì„œ í•™ìŠµ í›„ ì €ì¥ ìœ ë„.
    """
    if os.path.exists(rsf_path) and os.path.exists(rsf_scaler_path):
        rsf    = joblib.load(rsf_path)
        sc_rsf = joblib.load(rsf_scaler_path)
        return rsf, sc_rsf
    return None, None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. ì„ìƒ ë°ì´í„° ì „ì²˜ë¦¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def preprocess_clinical(
    df: pd.DataFrame,
    mice_imputer,
    scaler,
) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
    """
    ì„ìƒ CSV â†’ ANN ì…ë ¥ ë³€í™˜.
    ë°˜í™˜: X_scaled(34), X_health(25), X_cog(4), X_eng(5)
    """
    df = df.copy()
    # ì„±ë³„ ì¸ì½”ë”©
    df["PTGENDER"] = df["PTGENDER"].replace(
        {"Male": 1, "Female": 0, "M": 1, "F": 0}
    )

    # MICE ê²°ì¸¡ì¹˜ ëŒ€ì¹˜
    df_base      = df.reindex(columns=BASE_FEATS)
    imputed_arr  = mice_imputer.transform(df_base)
    df_imp       = pd.DataFrame(imputed_arr, columns=BASE_FEATS)

    # íŒŒìƒ ë³€ìˆ˜ ìƒì„± (2ì°¨ ANN í•™ìŠµ ì‹œì™€ ë™ì¼ ê³µì‹)
    df_imp["FAQ_LDELTA_ratio"] = df_imp["FAQTOTAL"] / (df_imp["LDELTOTAL"] + 1)
    df_imp["high_risk_score"]  = df_imp["CDRSB"] * 2 + df_imp["FAQTOTAL"] - df_imp["LDELTOTAL"]
    df_imp["med_cog_risk"]     = df_imp["dementia_med"] + df_imp["COG_DISORDER"]
    df_imp["CDRSB_MMSE_ratio"] = df_imp["CDRSB"] / (df_imp["MMSCORE"] + 1)
    df_imp["cog_composite"]    = df_imp["MMSCORE"] - df_imp["CDRSB"] * 2 - df_imp["FAQTOTAL"] * 0.5

    # ìŠ¤ì¼€ì¼ë§
    X_scaled = scaler.transform(df_imp[ALL_FEATS].values)
    X_health = X_scaled[:, :H_DIM].astype(np.float32)
    X_cog    = X_scaled[:, H_DIM:H_DIM + C_DIM].astype(np.float32)
    X_eng    = X_scaled[:, H_DIM + C_DIM:].astype(np.float32)

    return X_scaled, X_health, X_cog, X_eng


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. ì´ë¯¸ì§€ ì²˜ë¦¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def scan_images(img_root: str, folders: list[str] = ("MCI", "DM", "AD", "DM_or_AD")) -> pd.DataFrame:
    """
    ì´ë¯¸ì§€ í´ë” ìŠ¤ìº” â†’ DataFrame ë°˜í™˜.
    íŒŒì¼ëª… ê·œì¹™: {site}_{S}_{num}_{ImageID}_{slice}.png
    ìŠ¬ë¼ì´ìŠ¤ s2(ì¤‘ê°„) ë§Œ ì‚¬ìš©.
    """
    records = []
    for folder in folders:
        path = os.path.join(img_root, folder)
        if not os.path.isdir(path):
            continue
        for fname in sorted(os.listdir(path)):
            if not fname.lower().endswith(".png"):
                continue
            parts = fname.replace(".png", "").split("_")
            if len(parts) < 5:
                continue
            slice_num = int(parts[4].replace("s", ""))
            if slice_num != 2:          # ì¤‘ê°„ ìŠ¬ë¼ì´ìŠ¤ë§Œ
                continue
            records.append({
                "subject_id":    f"{parts[0]}_S_{parts[2]}",
                "Image.Data.ID": parts[3],
                "filepath":      os.path.join(path, fname),
            })
    return pd.DataFrame(records)


def load_image(path: str) -> np.ndarray:
    """ì´ë¯¸ì§€ íŒŒì¼ â†’ EfficientNet ì „ì²˜ë¦¬ ë°°ì—´ (224,224,3)"""
    img = tf.io.read_file(path)
    img = tf.image.decode_png(img, channels=3)
    img = tf.image.resize(img, IMG_SIZE)
    img = keras.applications.efficientnet.preprocess_input(
        tf.cast(img, tf.float32)
    )
    return img.numpy()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. ì•™ìƒë¸” ì˜ˆì¸¡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_ensemble(
    df_clinical: pd.DataFrame,
    img_root: str,
    cnn_model,
    ann_models: list,
    mice_imputer,
    scaler,
    batch_size: int = 32,
) -> pd.DataFrame:
    """
    ì„ìƒ CSV + ì´ë¯¸ì§€ í´ë” â†’ MCI/AD ì´ì§„ ë¶„ë¥˜ ê²°ê³¼ DataFrame.

    ë°˜í™˜ ì»¬ëŸ¼:
        subject_id, Image.Data.ID, label, true_binary,
        P_cnn_AD, P_ann_AD, P_ensemble_AD, pred_binary,
        risk_grade (Low/Medium/High, MCI ì˜ˆì¸¡ í™˜ìë§Œ)
    """
    # â”€â”€ ì„ìƒ ì „ì²˜ë¦¬ â”€â”€
    df_target = df_clinical[df_clinical["label"].isin([1, 2])].copy().reset_index(drop=True)
    _, X_health, X_cog, X_eng = preprocess_clinical(df_target, mice_imputer, scaler)

    # â”€â”€ ì´ë¯¸ì§€ ë§¤ì¹­ â”€â”€
    img_df = scan_images(img_root)
    df_target["img_id_clean"] = df_target["Image.Data.ID"].astype(str).str.strip()
    img_df["img_id_clean"]    = img_df["Image.Data.ID"].astype(str).str.strip()

    merged = df_target.reset_index(drop=False).merge(
        img_df[["img_id_clean", "filepath"]],
        on="img_id_clean", how="inner",
    ).rename(columns={"index": "orig_idx"})

    if len(merged) == 0:
        raise ValueError("ì´ë¯¸ì§€ì™€ ì„ìƒ ë°ì´í„° ë§¤ì¹­ ì‹¤íŒ¨. Image.Data.IDë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    # â”€â”€ CNN ë°°ì¹˜ ì˜ˆì¸¡ â”€â”€
    p_cnn = []
    n = len(merged)
    for start in range(0, n, batch_size):
        paths  = merged["filepath"].iloc[start:start + batch_size].tolist()
        imgs   = np.array([load_image(p) for p in paths])
        probs  = cnn_model(imgs, training=False).numpy()
        p_cnn.extend(probs[:, CNN_AD_IDX])

    # â”€â”€ ANN 5-seed í‰ê·  ì˜ˆì¸¡ â”€â”€
    idx = merged["orig_idx"].values
    seed_preds = [
        m.predict([X_health[idx], X_cog[idx], X_eng[idx]], verbose=0).flatten()
        for m in ann_models
    ]
    p_ann = np.mean(seed_preds, axis=0)

    # â”€â”€ ì•™ìƒë¸” â”€â”€
    p_ens   = CNN_WEIGHT * np.array(p_cnn) + ANN_WEIGHT * p_ann
    y_pred  = (p_ens >= 0.5).astype(int)
    y_true  = (merged["label"].values == 2).astype(int)

    result = merged[["subject_id", "Image.Data.ID", "label", "visit_order"]].copy()
    result["true_binary"]   = y_true
    result["P_cnn_AD"]      = np.array(p_cnn)
    result["P_ann_AD"]      = p_ann
    result["P_ensemble_AD"] = p_ens
    result["pred_binary"]   = y_pred       # 0=MCI, 1=AD

    # â”€â”€ MCI ì˜ˆì¸¡ í™˜ì ìœ„í—˜ë„ ë“±ê¸‰ (P_ensemble_AD ë¶„ìœ„ìˆ˜) â”€â”€
    mci_mask = result["pred_binary"] == 0
    if mci_mask.sum() > 0:
        q33 = result.loc[mci_mask, "P_ensemble_AD"].quantile(0.33)
        q66 = result.loc[mci_mask, "P_ensemble_AD"].quantile(0.66)
        result["risk_grade"] = pd.NA
        result.loc[mci_mask, "risk_grade"] = pd.cut(
            result.loc[mci_mask, "P_ensemble_AD"],
            bins=[-np.inf, q33, q66, np.inf],
            labels=["Low", "Medium", "High"],
        )

    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. ìƒì¡´ ë¶„ì„ â€” RSF í•™ìŠµ / ë¡œë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _build_survival_dataset(long_path: str, delta_path: str) -> pd.DataFrame:
    """ì¢…ë‹¨ ë°ì´í„° + delta í”¼ì²˜ â†’ RSF í•™ìŠµìš© ìƒì¡´ ë°ì´í„°ì…‹ ìƒì„±"""
    df_long  = pd.read_csv(long_path).sort_values(["RID", "Months_from_bl"])
    df_delta = pd.read_csv(delta_path)

    records = []
    for rid, visits in df_long.groupby("RID"):
        visits = visits.sort_values("Months_from_bl")
        mci_v  = visits[visits["DIAGNOSIS"] == "MCI"]
        dem_v  = visits[visits["DIAGNOSIS"] == "Dementia"]
        if len(mci_v) == 0:
            continue
        t0         = mci_v["Months_from_bl"].min()
        future_dem = dem_v[dem_v["Months_from_bl"] > t0]
        if len(future_dem) > 0:
            t_event = future_dem["Months_from_bl"].min() - t0
            event   = 1
        else:
            t_event = visits["Months_from_bl"].max() - t0
            event   = 0
        if t_event > 0:
            records.append({"RID": rid, "time": t_event, "event": event})

    surv_df = pd.DataFrame(records).merge(
        df_delta[["RID"] + RSF_FEATS], on="RID", how="left"
    )
    return surv_df.dropna(subset=RSF_FEATS)


def train_and_save_survival_models(
    long_path: str,
    delta_path: str,
    rsf_save_path: str,
    rsf_scaler_save_path: str,
) -> tuple:
    """
    RSF í•™ìŠµ í›„ ì €ì¥. ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰.
    ë°˜í™˜: (rsf_model, rsf_scaler, cox_model, surv_df)
    """
    from sksurv.ensemble import RandomSurvivalForest
    from sksurv.util import Surv

    surv_df = _build_survival_dataset(long_path, delta_path)
    print(f"ìƒì¡´ í•™ìŠµ ë°ì´í„°: {len(surv_df)}ëª… (ì „í™˜ {surv_df['event'].sum()}ëª…)")

    # ìŠ¤ì¼€ì¼ëŸ¬
    sc = StandardScaler()
    X  = sc.fit_transform(surv_df[RSF_FEATS].values)
    y  = Surv.from_arrays(
        event=surv_df["event"].astype(bool),
        time=surv_df["time"],
    )

    # RSF í•™ìŠµ
    rsf = RandomSurvivalForest(
        n_estimators=300, min_samples_leaf=10,
        max_features="sqrt", random_state=42, n_jobs=-1,
    )
    rsf.fit(X, y)

    # ì €ì¥
    joblib.dump(rsf, rsf_save_path)
    joblib.dump(sc,  rsf_scaler_save_path)
    print(f"âœ… RSF ëª¨ë¸ ì €ì¥: {rsf_save_path}")
    print(f"âœ… RSF ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥: {rsf_scaler_save_path}")

    return rsf, sc, surv_df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 7. ìƒì¡´ ì˜ˆì¸¡ (ê°œì¸ë³„)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def predict_individual_survival(
    ensemble_result: pd.DataFrame,
    delta_path: str,
    rsf_model,
    rsf_scaler,
    time_points: list[int] = [12, 24, 36, 48],
) -> pd.DataFrame:
    """
    ì•™ìƒë¸”ì—ì„œ MCIë¡œ ë¶„ë¥˜ëœ í™˜ì â†’ ê°œì¸ë³„ ì „í™˜ í™•ë¥  ì˜ˆì¸¡.

    ë°˜í™˜ ì»¬ëŸ¼:
        subject_id, risk_grade, P_ensemble_AD,
        P_convert_12mo, P_convert_24mo, P_convert_36mo, P_convert_48mo,
        final_risk_grade
    """
    mci_df = ensemble_result[ensemble_result["pred_binary"] == 0].copy()
    if len(mci_df) == 0:
        return pd.DataFrame()

    # delta í”¼ì²˜ ì—°ê²°
    df_delta = pd.read_csv(delta_path)
    mci_df["RID_parsed"] = (
        mci_df["subject_id"].str.extract(r"(\d+)$")
        .astype(float).astype("Int64")
    )
    mci_df = mci_df.merge(
        df_delta[["RID"] + RSF_FEATS].rename(columns={"RID": "RID_parsed"}),
        on="RID_parsed", how="left",
    )
    # ì¢…ë‹¨ ë°ì´í„° ì—†ëŠ” í™˜ìëŠ” medianìœ¼ë¡œ ëŒ€ì²´
    for col in RSF_FEATS:
        mci_df[col] = mci_df[col].fillna(mci_df[col].median())

    # RSF ê°œì¸ë³„ ì˜ˆì¸¡
    X_mci    = rsf_scaler.transform(mci_df[RSF_FEATS].values)
    surv_fns = rsf_model.predict_survival_function(X_mci, return_array=False)

    for t in time_points:
        mci_df[f"P_convert_{t}mo"] = [1 - fn(t) for fn in surv_fns]

    # ìµœì¢… ìœ„í—˜ë„ ë“±ê¸‰ (24ê°œì›” ê¸°ì¤€)
    def _final_grade(p24: float) -> str:
        if p24 < 0.15:   return "Low"
        elif p24 < 0.40: return "Medium"
        return "High"

    mci_df["final_risk_grade"] = mci_df["P_convert_24mo"].apply(_final_grade)

    keep = (
        ["subject_id", "risk_grade", "P_ensemble_AD"]
        + [f"P_convert_{t}mo" for t in time_points]
        + ["final_risk_grade"]
    )
    return mci_df[keep].reset_index(drop=True)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 8. ê²°ê³¼ ì‹œê°í™”
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def plot_ensemble_result(ensemble_df: pd.DataFrame, save_path: str = None):
    """ì•™ìƒë¸” ê²°ê³¼ ì‹œê°í™” (P(AD) ë¶„í¬ + ìœ„í—˜ë„ ë“±ê¸‰ íŒŒì´)"""
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # P(AD) ë¶„í¬
    ax = axes[0]
    colors = {"MCI": "steelblue", "AD": "salmon"}
    for pred, color in colors.items():
        mask = ensemble_df["pred_binary"] == (0 if pred == "MCI" else 1)
        ax.hist(ensemble_df.loc[mask, "P_ensemble_AD"],
                bins=30, alpha=0.65, color=color, label=pred, edgecolor="white")
    ax.set_xlabel("P(AD) â€” ì•™ìƒë¸” í™•ë¥ ")
    ax.set_title("ì˜ˆì¸¡ ë¶„í¬")
    ax.legend()

    # ìœ„í—˜ë„ íŒŒì´ (MCI í™˜ìë§Œ)
    ax2 = axes[1]
    mci = ensemble_df[ensemble_df["pred_binary"] == 0]
    if "risk_grade" in mci.columns and mci["risk_grade"].notna().any():
        counts = mci["risk_grade"].value_counts().reindex(["Low", "Medium", "High"])
        ax2.pie(counts, labels=counts.index, autopct="%1.1f%%",
                colors=["#2ecc71", "#f39c12", "#e74c3c"])
        ax2.set_title("MCI í™˜ì ì•™ìƒë¸” ìœ„í—˜ë„ ë¶„í¬")

    plt.tight_layout()
    if save_path:
        fig.savefig(save_path, dpi=150)
        print(f"ğŸ“Š ì•™ìƒë¸” ê²°ê³¼ ì €ì¥: {save_path}")
    return fig


def plot_survival_result(survival_df: pd.DataFrame, save_path: str = None):
    """ê°œì¸ë³„ ìƒì¡´ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” (ì „í™˜ í™•ë¥  ë¶„í¬ by ìœ„í—˜ë„ ê·¸ë£¹)"""
    time_cols = [c for c in survival_df.columns if c.startswith("P_convert_")]
    if not time_cols:
        return None

    colors = {"Low": "#2ecc71", "Medium": "#f39c12", "High": "#e74c3c"}
    fig, axes = plt.subplots(1, len(time_cols), figsize=(5 * len(time_cols), 5))
    if len(time_cols) == 1:
        axes = [axes]

    for ax, col in zip(axes, time_cols):
        label = col.replace("P_convert_", "").replace("mo", "ê°œì›”")
        for grade, color in colors.items():
            sub = survival_df[survival_df["final_risk_grade"] == grade][col]
            if len(sub) == 0:
                continue
            ax.hist(sub, bins=20, alpha=0.6, color=color, label=grade, edgecolor="white")
        ax.set_title(f"{label} ì „í™˜ í™•ë¥  ë¶„í¬")
        ax.set_xlabel("ì „í™˜ í™•ë¥ ")
        ax.set_ylabel("í™˜ì ìˆ˜")
        ax.legend()

    plt.suptitle("MCI í™˜ì ê°œì¸ë³„ ì¹˜ë§¤ ì „í™˜ í™•ë¥  (RSF)", y=1.02, fontsize=13)
    plt.tight_layout()
    if save_path:
        fig.savefig(save_path, dpi=150)
        print(f"ğŸ“Š ìƒì¡´ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥: {save_path}")
    return fig
